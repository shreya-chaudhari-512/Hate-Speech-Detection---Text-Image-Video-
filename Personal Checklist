âœ… Recommended Dataset Sizes
ğŸ”¹ Image Hate Detection

Total images: 8,000 â€“ 12,000

Train: 70%

Validation: 15%

Test: 15%

Why this works:

Enough for CNN + BERT

Trains in reasonable GPU time

Easy to justify academically

ğŸ“Œ You can say in viva:

â€œA balanced subset was selected to reduce computational overhead while preserving diversity.â€

ğŸ”¹ Violence / Gore Detection (Frames)

Total frames: 6,000 â€“ 10,000

Classes:

Non-violent

Violent

Gore

You do NOT need 100k frames.

ğŸ”¹ Video Dataset

Videos: 150 â€“ 300 total

Frame extraction: 1â€“3 FPS

This is more than enough for a college project.



2ï¸âƒ£ GPU TRAINING CHECKLIST (PRINT THIS)

Use this checklist every time you go to the college GPU PC.

ğŸ”¥ Before Training

âœ” Dataset copied
âœ” Repo pulled from GitHub
âœ” Virtual environment created
âœ” GPU detected (nvidia-smi)
âœ” Correct CUDA version
âœ” Batch size adjusted to GPU memory

ğŸ”¥ During Training

âœ” Train on subset first
âœ” Save checkpoints every few epochs
âœ” Log metrics (loss, F1)
âœ” Avoid training overnight without supervision

ğŸ”¥ After Training

âœ” Save model weights
âœ” Save confusion matrix
âœ” Export logs/plots
âœ” Push results to GitHub (NOT datasets)


ORDER ::
1ï¸âƒ£ Finalize datasets
2ï¸âƒ£ Create repo + .gitignore
3ï¸âƒ£ Implement image-only pipeline
4ï¸âƒ£ Test OCR + text model locally
5ï¸âƒ£ Train image model on GPU
6ï¸âƒ£ Extend to video
7ï¸âƒ£ Add violence + gore
